{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "amuNToJi4Rez"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wbKBHkYG4MoE"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from collections import Counter\n",
        "\n",
        "input_file_segments = '/content/drive/MyDrive/Project/ExtractedSegments_1s_set1.npy'\n",
        "input_file_labels = '/content/drive/MyDrive/Project/ExtractedLabelas_1s_set1.npy'\n",
        "\n",
        "loaded_segments = np.load(input_file_segments, allow_pickle=True)\n",
        "loaded_labels = np.load(input_file_labels, allow_pickle=True)\n",
        "\n",
        "print(f'Total segments loaded: {len(loaded_segments)}')\n",
        "print(f'Total labels loaded: {len(loaded_labels)}')\n",
        "print(f'Sample segment shape: {loaded_segments[0].shape}')\n",
        "print(f'Sample label: {loaded_labels[0]}')\n",
        "\n",
        "label_counts = Counter(loaded_labels)\n",
        "print(f'Label counts: {label_counts}')\n",
        "\n",
        "max_count = max(label_counts.values())\n",
        "\n",
        "def add_gaussian_noise(data, mean=0, std_dev=0.05):\n",
        "    noise = np.random.normal(mean, std_dev, data.shape)\n",
        "    return data + noise\n",
        "\n",
        "augmented_segments = []\n",
        "augmented_labels = []\n",
        "\n",
        "for segment, label in zip(loaded_segments, loaded_labels):\n",
        "    if segment.shape == (125, 16):\n",
        "        augmented_segments.append(segment)\n",
        "        augmented_labels.append(label)\n",
        "    else:\n",
        "        print(f\"Skipping segment with invalid shape: {segment.shape}\")\n",
        "\n",
        "for label, count in label_counts.items():\n",
        "    if count < max_count:\n",
        "        label_segments = [seg for seg, lbl in zip(loaded_segments, loaded_labels) if lbl == label]\n",
        "\n",
        "        num_samples_needed = max_count - count\n",
        "\n",
        "        for _ in range(num_samples_needed):\n",
        "            segment = label_segments[np.random.randint(len(label_segments))]\n",
        "            noisy_segment = add_gaussian_noise(segment)\n",
        "\n",
        "            if noisy_segment.shape == (125, 16):\n",
        "                augmented_segments.append(noisy_segment)\n",
        "                augmented_labels.append(label)\n",
        "            else:\n",
        "                print(f\"Generated segment with invalid shape: {noisy_segment.shape}\")\n",
        "\n",
        "augmented_segments = np.array(augmented_segments)\n",
        "augmented_labels = np.array(augmented_labels)\n",
        "\n",
        "print(f'Augmented data shape: {augmented_segments.shape}')\n",
        "print(f'Augmented labels shape: {augmented_labels.shape}')\n",
        "print(f'New label counts: {Counter(augmented_labels)}')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = augmented_segments\n",
        "final_labels = augmented_labels"
      ],
      "metadata": {
        "id": "bPgs15dM4VEY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, ReLU, MaxPooling2D\n",
        "from tensorflow.keras.layers import Flatten, Dense, Dropout, Reshape, LSTM\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, concatenate\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, DepthwiseConv2D, BatchNormalization, Activation, Dropout, Flatten, Dense, MaxPooling2D\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "import pandas as pd\n"
      ],
      "metadata": {
        "id": "Pi4CUjYj4V2n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "target_labels = ['Impasse', 'Doing Other Task']\n",
        "\n",
        "final_labels = np.array(final_labels)\n",
        "\n",
        "mask = np.isin(final_labels, target_labels)\n",
        "\n",
        "filtered_data = data[mask]\n",
        "filtered_labels = final_labels[mask]\n",
        "\n",
        "print(f\"Filtered Data Shape: {filtered_data.shape}\")\n",
        "print(f\"Filtered Labels Shape: {filtered_labels.shape}\")"
      ],
      "metadata": {
        "id": "GtoOOvvn4uMv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Input, Conv1D, MaxPooling1D, Flatten, Dense, concatenate\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "def tsception(input_shape=(125, 16), num_classes=5):\n",
        "\n",
        "    inputs = Input(shape=input_shape)\n",
        "\n",
        "    t1 = Conv1D(16, kernel_size=3, activation='relu', padding='same')(inputs)\n",
        "    t2 = Conv1D(16, kernel_size=5, activation='relu', padding='same')(inputs)\n",
        "    t3 = Conv1D(16, kernel_size=7, activation='relu', padding='same')(inputs)\n",
        "\n",
        "    concatenated = concatenate([t1, t2, t3])\n",
        "\n",
        "    pooled = MaxPooling1D(pool_size=20)(concatenated)\n",
        "\n",
        "    flat = Flatten()(pooled)\n",
        "\n",
        "    dense = Dense(64, activation='relu')(flat)\n",
        "    outputs = Dense(num_classes, activation='softmax')(dense)\n",
        "\n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "FbAuGVyWAXm3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow.keras.backend as K\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, ReLU, MaxPooling2D\n",
        "from tensorflow.keras.layers import Flatten, Dense, Dropout, Reshape, LSTM\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, concatenate\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, DepthwiseConv2D, BatchNormalization, Activation, Dropout, Flatten, Dense, MaxPooling2D\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "import pandas as pd\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "encoded_labels = label_encoder.fit_transform(filtered_labels)\n",
        "\n",
        "\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "skf = StratifiedKFold(n_splits=5, random_state=42, shuffle=True)\n",
        "for train_index, test_index in skf.split(filtered_data, encoded_labels):\n",
        "    X_train, X_test = filtered_data[train_index], filtered_data[test_index]\n",
        "    y_train, y_test = encoded_labels[train_index], encoded_labels[test_index]\n",
        "\n",
        "X_train = np.array(X_train, dtype=np.float32)\n",
        "X_test = np.array(X_test, dtype=np.float32)\n",
        "y_train = np.array(y_train, dtype=np.int32)\n",
        "y_test = np.array(y_test, dtype=np.int32)\n",
        "K.clear_session()\n",
        "\n",
        "main_model = tsception(input_shape=(125, 16))\n",
        "main_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history = main_model.fit(\n",
        "    X_train,\n",
        "    y_train,\n",
        "    validation_data=(X_test, y_test),\n",
        "    epochs=50,\n",
        "    batch_size=32,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "test_loss, test_accuracy = main_model.evaluate(X_test, y_test)\n",
        "print(f'Test Accuracy: {test_accuracy:.4f}')\n",
        "\n",
        "test_loss_train, test_accuracy_train = main_model.evaluate(X_train, y_train)\n",
        "print(f'Train Accuracy: {test_accuracy_train:.4f}')"
      ],
      "metadata": {
        "id": "5e7Lyv9vArEl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, classification_report\n",
        "\n",
        "y_pred_prob = main_model.predict(X_test)\n",
        "y_pred = (y_pred_prob > 0.5).astype(int)\n",
        "\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n",
        "\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "plt.figure(figsize=(6, 5))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=['Class 0', 'Class 1'], yticklabels=['Class 0', 'Class 1'])\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "zqMFGKEw5Utb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import roc_curve, auc, confusion_matrix\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "\n",
        "# Generate predictions (probabilities)\n",
        "y_pred_prob = main_model.predict(X_test)\n",
        "y_pred = (y_pred_prob > 0.5).astype(int)  # Convert probabilities to binary predictions\n",
        "\n",
        "# ROC Curve\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC Curve (AUC = {roc_auc:.2f})')\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
        "plt.legend(loc='lower right')\n",
        "plt.grid(alpha=0.3)\n",
        "plt.show()\n",
        "\n",
        "# Confusion Matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "plt.figure(figsize=(6, 5))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=[\"Class 0\", \"Class 1\"], yticklabels=[\"Class 0\", \"Class 1\"])\n",
        "plt.xlabel('Predicted Labels')\n",
        "plt.ylabel('True Labels')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "oNN-2JF3f34_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "X_test_new= main_model.predict(X_test)\n",
        "\n",
        "\n",
        "X_test_features = np.concatenate([X_test_new], axis=1)\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
        "import pandas as pd\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "classifiers = {\n",
        "    \"SVM\": SVC(),\n",
        "    \"Random Forest\": RandomForestClassifier(),\n",
        "    \"Gradient Boosting\": GradientBoostingClassifier(),\n",
        "    \"AdaBoost\": AdaBoostClassifier(),\n",
        "    \"XGBoost\": XGBClassifier(),\n",
        "    \"K-Neighbors\": KNeighborsClassifier(),\n",
        "    \"Logistic Regression\": LogisticRegression(),\n",
        "    \"Naive Bayes\": GaussianNB()\n",
        "}\n",
        "\n",
        "results = {}\n",
        "\n",
        "for clf_name, clf in classifiers.items():\n",
        "    clf.fit(X_train_features, y_train)\n",
        "\n",
        "    y_pred_train = clf.predict(X_train_features)\n",
        "    y_pred_test = clf.predict(X_test_features)\n",
        "\n",
        "    train_accuracy = accuracy_score(y_train, y_pred_train)\n",
        "    train_precision = precision_score(y_train, y_pred_train, average='weighted')\n",
        "    train_recall = recall_score(y_train, y_pred_train, average='weighted')\n",
        "    train_f1 = f1_score(y_train, y_pred_train, average='weighted')\n",
        "\n",
        "    test_accuracy = accuracy_score(y_test, y_pred_test)\n",
        "    test_precision = precision_score(y_test, y_pred_test, average='weighted')\n",
        "    test_recall = recall_score(y_test, y_pred_test, average='weighted')\n",
        "    test_f1 = f1_score(y_test, y_pred_test, average='weighted')\n",
        "\n",
        "    print(f\"\\nClassifier: {clf_name}\")\n",
        "    print(f\"Train Accuracy: {train_accuracy:.4f}\")\n",
        "    print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
        "    print(f\"Test Precision: {test_precision:.4f}\")\n",
        "    print(f\"Test Recall: {test_recall:.4f}\")\n",
        "    print(f\"Test F1 Score: {test_f1:.4f}\")\n",
        "    print(\"Classification Report (Test Data):\")\n",
        "    print(classification_report(y_test, y_pred_test, target_names=label_encoder.classes_))\n",
        "\n",
        "    results[clf_name] = {\n",
        "        \"Train Accuracy\": train_accuracy,\n",
        "        \"Test Accuracy\": test_accuracy,\n",
        "        \"Train Precision\": train_precision,\n",
        "        \"Train Recall\": train_recall,\n",
        "        \"Train F1 Score\": train_f1,\n",
        "        \"Test Precision\": test_precision,\n",
        "        \"Test Recall\": test_recall,\n",
        "        \"Test F1 Score\": test_f1\n",
        "    }\n",
        "\n",
        "results_df = pd.DataFrame(results).T\n",
        "print(\"\\nSummary of Classifier Performance:\")\n",
        "print(results_df)"
      ],
      "metadata": {
        "id": "nbXVDWnY6Gs6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}